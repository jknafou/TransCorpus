# TransCorpus
**TransCorpus** is a scalable, production-ready API and CLI toolkit for large-scale parallel translation, preprocessing, and corpus management. It supports multi-GPU translation, robust checkpointing, and safe concurrent downloads, making it ideal for research and industry-scale machine translation workflows.

# Features
- üöÄ **Multi-GPU** and multi-process translation
- üì¶ Corpus downloading and preprocessing
- üîí Safe, **resumable**, and concurrent file downloads
- üß© **Split** and checkpoint management for large corpora
- üõ†Ô∏è Easy deployment and extensibility
- üñ•Ô∏è Cross-platform: Linux, macOS, Windows

# Quick Start
1. Clone and Install
```bash
git clone https://github.com/jknafou/TransCorpus.git
cd TransCorpus
UV_INDEX_STRATEGY=unsafe-best-match rye sync
source .venv/bin/activate
```
2. Download a Corpus

```bash
transcorpus download-corpus [corpus_name]
```
3. Preprocess the corpus by splits
```bash
transcorpus preprocess [corpus_name] [language] --num-split 100
```
4. Translate (and preprocess if not done) the corpus by split
```bash
transcorpus translate [corpus_name] [language] --num-split 100
```
5. Preview a corpus with two languages next to each other:
```bash
transcorpus preview [corpus_name] [language1] Opt[language2]
```

<br>
<div align="center">
  <img src="https://transcorpus.s3.text-analytics.ch/sidepreview.png" alt="Example of two languages next to each other" width="500"/>
</div>
<br>

A demo mode can be tested using the -d flag for each command.

## Preprocess and Translate (Multi-GPU Example)
The following example translates the bio corpus (PubMed) of about 30GB, preprocessing it with 4 parallel workers, while translating each available split with two GPUs of different sizes. It can easily be modified to one needs. When deployed on an HPC cluster, for example with SLURM, it will automatically resume from where it left off in the previous run. With shared memory, multiple GPUs from different nodes can work simultaneously.
```bash
# Preprocess with 4 workers iteratively, split into 20 parts (here in demo mode)
./example/multi_GPU.sh bio de 4 20

```

# Research-Proven Performance: TransBERT(-bio-fr)
## Paper to be submitted to EMNLP2025
TransCorpus enables the training of state-of-the-art language models through synthetic translation. For example, TransBERT achieved superior performance by leveraging corpus translation with this toolkit. A paper detailing these results will be submitted to EMNLP 2025. üìù [Current Paper Version](https://transbert.s3.text-analytics.ch/TransBERT.pdf)

## üß¨ Pretrained Models
Looking for pretrained models built with TransCorpus?  
Check out [TransBERT-bio-fr on Hugging Face ü§ó](https://huggingface.co/jknafou/TransBERT-bio-fr), a French biomedical language model trained entirely on synthetic translations generated by this toolkit.


## New corpus upload
One can easily add its own corpus (along with a demo) to the repo following the same schema of ```domains.json```:
```json
    "bio": {
        "database": {
            "file": "https://transcorpus.s3.text-analytics.ch/bibmed.tar.gz"
        },
        "corpus": {
            "file":
                "https://transcorpus.s3.text-analytics.ch/title_abstract_en.txt"
            ,
            "demo":
                "https://transcorpus.s3.text-analytics.ch/1k_sample.txt"
        },
        "id": {
            "file":
                "https://transcorpus.s3.text-analytics.ch/PMID.txt"
            ,
            "demo":
                "https://transcorpus.s3.text-analytics.ch/PMID_1k_sample.txt"
        },
        "language": "en"
    }
```
Where each line of the corpus is a different document. For the moment, a life-science corpus is available comprising about 28GB of raw text, 22M of abstracts from PubMed. The database it is made of can also be downloaded using ```transcorpus download-database bio```.

# Deployment
## Requirements:

- Python 3.10+
- rye (for dependency management)
- CUDA-enabled GPUs (for multi-GPU translation)

## Contributing
Pull requests and issues are welcome!

## License
MIT License

## Acknowledgements
- fairseq
- PyTorch
- rye

**TransCorpus** makes large-scale, robust translation easy and reproducible. 


# Work in Progress
- [ ] create a pypi package
- [ ] write tests
- [ ] avoid unloading the GPU between split and give the model a new binary file to translate
- [ ] limit fairseq verbose
- [ ] clean code + pass test
